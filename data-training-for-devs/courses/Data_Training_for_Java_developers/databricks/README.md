# Databricks

## Topics to cover:

1. Databricks basics
2. Transform Data with Spark
3. Manage Data with Delta Lake 
4. Build Data Pipelines with Delta Live Tables
5. Deploy Workloads with Databricks Workflows
6. Manage Data Access with Unity Catalog

## Materials:

The module includes access to the **Databricks Partner training**: [Data Engineering with Databricks](https://partner-academy.databricks.com/learn/course/internal/view/elearning/1266/data-engineering-with-databricks).

**Note** that this course provides context for how to perform the actions within it **using both Spark SQL and PySpark**. If you are interested **in one over the other**, feel free to focus on that content (and skip the videos that are not relevant to you).

**Note**: if you have access only to the Community Databricks edition and can't execute some practical tasks  - please, feel free to review related code and tasks without running them after informing your program run coordinator.

### Prerequisites:
#### Prerequisites for both versions of this course (Spark SQL and PySpark):

* Beginner familiarity with cloud computing concepts (virtual machines, object storage, etc.)
* Production experience working with data warehouses and data lakes
* Familiarity with basic SQL concepts (select, filter, groupby, join, etc)


#### Additional prerequisites for the Python version of this course (PySpark):

* Beginner programming experience with Python (syntax, conditions, loops, functions)
* Beginner programming experience with the Spark DataFrame API:
* Configure DataFrameReader and DataFrameWriter to read and write data
* Express query transformations using DataFrame methods and Column expressions
* Navigate the Spark documentation to identify built-in functions for various transformations and data types


The PySpark programming skills required for the Python version of this course can be learned by taking the Get Started with PySpark Programming course by Databricks Academy.


In case of any issues with access, please, contact [the L&D team](mailto:AskLearn@epam.com).
