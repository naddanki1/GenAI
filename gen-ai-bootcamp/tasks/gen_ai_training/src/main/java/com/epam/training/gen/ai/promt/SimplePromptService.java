package com.epam.training.gen.ai.promt;

import com.azure.ai.openai.OpenAIAsyncClient;
import com.azure.ai.openai.models.ChatCompletionsOptions;
import com.azure.ai.openai.models.ImageGenerationData;
import com.azure.ai.openai.models.ImageGenerationOptions;
import com.azure.ai.openai.models.ImageSize;
import com.epam.training.gen.ai.configuration.ModelConfig;
import com.epam.training.gen.ai.strategy.ChatCompletionStrategy;
import com.microsoft.semantickernel.Kernel;
import com.microsoft.semantickernel.orchestration.InvocationContext;
import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;
import com.microsoft.semantickernel.services.chatcompletion.ChatCompletionService;
import com.microsoft.semantickernel.services.chatcompletion.ChatHistory;
import com.microsoft.semantickernel.services.chatcompletion.ChatMessageContent;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import org.springframework.util.CollectionUtils;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;


/**
 * Service class for generating chat completions using Azure OpenAI.
 * <p>
 * This service interacts with the Azure OpenAI API to generate chat completions
 * based on a static greeting message. It retrieves responses from the AI model
 * and logs them.
 */
@Slf4j
@Service
public class SimplePromptService {

    private final OpenAIAsyncClient aiAsyncClient;
    private final Map<String, String> modelDeployments;
    private final ChatCompletionStrategy chatCompletionStrategy;
    private final Kernel kernel;
    private final ChatCompletionService chatCompletionService;
    @Autowired
    ChatHistory chatHistory;

    public SimplePromptService(OpenAIAsyncClient aiAsyncClient,
                               ModelConfig modelConfig,
                               ChatCompletionStrategy chatCompletionStrategy,
                               Kernel kernel, ChatCompletionService chatCompletionService) {
        this.aiAsyncClient = aiAsyncClient;
        this.modelDeployments = modelConfig.getModels();
        this.chatCompletionStrategy = chatCompletionStrategy;
        this.kernel = kernel;
        this.chatCompletionService = chatCompletionService;
    }

    /**
     * Generates chat completions for a given prompt.
     * <p>
     * This method sends the provided prompt to the Azure OpenAI service,
     * waits for the response asynchronously, and returns a list of response messages.
     * </p>
     * @param prompt the text input that serves as the prompt for generating the response
     * @param model key
     * @return a list of response messages generated by the OpenAI model
     */
    public List<String> getChatCompletions(String prompt) {

        chatHistory.addUserMessage(prompt);
        List<ChatMessageContent<?>> response = fetchChatResponse(chatCompletionService, chatHistory,
                kernel);
        List<String> chats = new ArrayList<>();

        if(!CollectionUtils.isEmpty(response)){
            log.info(response.get(0).getContent());
            chatHistory.addSystemMessage(response.get(0).getContent());
            chats = response.stream()
                    .map(ChatMessageContent::getContent)
                    .collect(Collectors.toList());
        }

        return chats;
    }
    private List<ChatMessageContent<?>> fetchChatResponse(
            ChatCompletionService chatCompletionService,
            ChatHistory history,
            Kernel kernel
    ) {
        InvocationContext optionalInvocationContext = InvocationContext.builder()
                .withPromptExecutionSettings(chatCompletionStrategy.getDefaultSettings()).build();
        return chatCompletionService.getChatMessageContentsAsync(history, kernel,
                optionalInvocationContext).block();
    }

}
