package com.epam.training.gen.ai.promt;

import com.azure.ai.openai.OpenAIAsyncClient;
import com.azure.ai.openai.models.ChatCompletionsOptions;
import com.azure.ai.openai.models.ChatRequestMessage;
import com.azure.ai.openai.models.ChatRequestUserMessage;
import com.epam.training.gen.ai.strategy.ChatCompletionStrategy;
import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;
import com.microsoft.semantickernel.services.chatcompletion.ChatCompletionService;
import com.microsoft.semantickernel.services.chatcompletion.ChatHistory;
import com.microsoft.semantickernel.services.chatcompletion.ChatMessageContent;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;

import java.util.ArrayList;
import java.util.List;


/**
 * Service class for generating chat completions using Azure OpenAI.
 * <p>
 * This service interacts with the Azure OpenAI API to generate chat completions
 * based on a static greeting message. It retrieves responses from the AI model
 * and logs them.
 */
@Slf4j
@Service
public class SimplePromptService {

    private final OpenAIAsyncClient aiAsyncClient;
    private final String deploymentOrModelName;
    private final ChatCompletionStrategy chatCompletionStrategy;
    private final ChatHistoryService chatHistoryService;

    public SimplePromptService(OpenAIAsyncClient aiAsyncClient,
                               @Value("${client-azureopenai-deployment-name}") String deploymentOrModelName,
                               ChatCompletionStrategy chatCompletionStrategy,
                               ChatHistoryService chatHistoryService) {
        this.aiAsyncClient = aiAsyncClient;
        this.deploymentOrModelName = deploymentOrModelName;
        this.chatCompletionStrategy = chatCompletionStrategy;
        this.chatHistoryService = chatHistoryService;
    }

    /**
     * Generates chat completions for a given prompt.
     * <p>
     * This method sends the provided prompt to the Azure OpenAI service,
     * waits for the response asynchronously, and returns a list of response messages.
     * </p>
     *
     * @param prompt the text input that serves as the prompt for generating the response
     * @return a list of response messages generated by the OpenAI model
     */
    public List<String> getChatCompletions(String prompt) {
        PromptExecutionSettings settings = chatCompletionStrategy.getDefaultSettings();
        chatHistoryService.addUserMessage(prompt);
        var completions = aiAsyncClient
                .getChatCompletions(
                        deploymentOrModelName,
                        new ChatCompletionsOptions(
                                chatHistoryService.getChatHistory())
                                .setMaxTokens(settings.getMaxTokens())
                                .setTemperature(settings.getTemperature()))

                .block();
        var messages = completions.getChoices().stream()
                .map(c -> c.getMessage().getContent())
                .toList();
        if (!messages.isEmpty()) {
            chatHistoryService.addSystemMessage(messages.get(0));
        }
        log.info(messages.toString());
        return messages;
    }

}
